{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d3b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nclabterm1/refresh/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.36 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.36 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 182.88 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 320.08 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 403.69 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 320.08 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 337.73 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 354.28 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 355.84 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 354.28 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 355.84 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 349.55 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 337.76 examples/s]\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 349.55 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 337.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict, Features, Value, Sequence\n",
    "\n",
    "BASE = Path(\"./\") \n",
    "NAMES = [\"my_korean\", \"my_race_middle\", \"my_race_high\", \"my_cloth\"]\n",
    "\n",
    "record = {\n",
    "    \"example_id\": \"0\",\n",
    "    \"article\": \"this is a mock article\",\n",
    "    \"answer\": \"C\",\n",
    "    \"question\": \"this is a mock question\",\n",
    "    \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "}\n",
    "\n",
    "features = Features({\n",
    "    \"example_id\": Value(\"string\"),\n",
    "    \"article\": Value(\"string\"),\n",
    "    \"answer\": Value(\"string\"),\n",
    "    \"question\": Value(\"string\"),\n",
    "    \"options\": Sequence(Value(\"string\")),\n",
    "})\n",
    "\n",
    "saved_paths = []\n",
    "for name in NAMES:\n",
    "    out_dir = BASE / name\n",
    "    out_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_ds = Dataset.from_list([record], features=features)\n",
    "    valid_ds = Dataset.from_list([record], features=features)\n",
    "\n",
    "    dsd = DatasetDict({\"train\": train_ds, \"validation\": valid_ds})\n",
    "    dsd.save_to_disk(str(out_dir))  \n",
    "\n",
    "    saved_paths.append(str(out_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5670d72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 315.81 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 353.62 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 315.81 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 353.62 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 363.27 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 343.74 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 343.74 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 325.87 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 325.87 examples/s]\n",
      "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 348.54 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved datasets:\n",
      "분류 모델 용/cloth\n",
      "분류 모델 용/korean\n",
      "분류 모델 용/race_high_long\n",
      "분류 모델 용/race_high_short\n",
      "분류 모델 용/race_middle_long\n",
      "분류 모델 용/race_middle_short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BASE = Path(\"./분류 모델 용\")\n",
    "NAMES = [\n",
    "    \"cloth\",\n",
    "    \"korean\",\n",
    "    \"race_high_long\",\n",
    "    \"race_high_short\",\n",
    "    \"race_middle_long\",\n",
    "    \"race_middle_short\",\n",
    "]\n",
    "features = Features({\n",
    "    \"example_id\": Value(\"string\"),\n",
    "    \"article\": Value(\"string\"),\n",
    "    \"answer\": Value(\"string\"),\n",
    "    \"question\": Value(\"string\"),\n",
    "    \"options\": Sequence(Value(\"string\")),\n",
    "})\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "saved = []\n",
    "for name in NAMES:\n",
    "    out_dir = BASE / name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    test_ds = Dataset.from_list([record], features=features)\n",
    "    dsd = DatasetDict({\"test\": test_ds})\n",
    "    dsd.save_to_disk(str(out_dir))  # HF 로컬 포맷(Arrow 백엔드)\n",
    "\n",
    "    saved.append(str(out_dir))\n",
    "\n",
    "print(\"Saved datasets:\")\n",
    "for p in saved:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58bb1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 302.60 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 322.56 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 302.60 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 322.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../gemma-STaR/dataset/loop0_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 287.89 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 323.36 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 287.89 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 323.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../phi-STaR/dataset/loop0_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 320.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 320.37 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 310.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../genai_api_send/cloth_with_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "record = {\n",
    "    \"example_id\": \"0\",\n",
    "    \"article\": \"this is a mock article\",\n",
    "    \"answer\": \"C\",\n",
    "    \"question\": \"this is a mock question\",\n",
    "    \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "    \"pred\": \"mock, answer is C\",\n",
    "}\n",
    "\n",
    "features = Features({\n",
    "    \"example_id\": Value(\"string\"),\n",
    "    \"article\": Value(\"string\"),\n",
    "    \"answer\": Value(\"string\"),\n",
    "    \"question\": Value(\"string\"),\n",
    "    \"options\": Sequence(Value(\"string\")),\n",
    "    \"pred\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "ds_one = Dataset.from_list([record], features=features)\n",
    "dsd = DatasetDict({\"train\": ds_one, \"validation\": ds_one})\n",
    "\n",
    "for base in [\"../gemma-STaR/dataset/loop0_dataset\", \"../phi-STaR/dataset/loop0_dataset\", \"../genai_api_send/cloth_with_pred\"]:\n",
    "    out_dir = Path(base)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dsd.save_to_disk(str(out_dir))\n",
    "    print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf8ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 27049.56 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 27049.56 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 22579.16 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 22579.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_final/dataset/cloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 18031.49 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 26890.01 examples/s]\n",
      "\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 26890.01 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_final/dataset/korean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 28029.30 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 28029.30 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 18155.59 examples/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_final/dataset/race_high_long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 28876.45 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 28876.45 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 18346.98 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 18346.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_final/dataset/race_high_short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 29963.59 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 29963.59 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 20654.47 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 20654.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_final/dataset/race_middle_long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 27833.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 27833.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 26163.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_final/dataset/race_middle_short\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "records = [\n",
    "    {\n",
    "        \"example_id\": \"0\",\n",
    "        \"article\": \"this is a mock article\",\n",
    "        \"answer\": \"C\",\n",
    "        \"question\": \"this is a mock question\",\n",
    "        \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "        \"example_type\": \"cloth\",\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"0\",\n",
    "        \"article\": \"this is a mock article\",\n",
    "        \"answer\": \"C\",\n",
    "        \"question\": \"this is a mock question\",\n",
    "        \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "        \"example_type\": \"korean\",\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"0\",\n",
    "        \"article\": \"this is a mock article\",\n",
    "        \"answer\": \"C\",\n",
    "        \"question\": \"this is a mock question\",\n",
    "        \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "        \"example_type\": \"race_high_long\",\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"0\",\n",
    "        \"article\": \"this is a mock article\",\n",
    "        \"answer\": \"C\",\n",
    "        \"question\": \"this is a mock question\",\n",
    "        \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "        \"example_type\": \"race_high_short\",\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"0\",\n",
    "        \"article\": \"this is a mock article\",\n",
    "        \"answer\": \"C\",\n",
    "        \"question\": \"this is a mock question\",\n",
    "        \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "        \"example_type\": \"race_middle_long\",\n",
    "    },\n",
    "    {\n",
    "        \"example_id\": \"0\",\n",
    "        \"article\": \"this is a mock article\",\n",
    "        \"answer\": \"C\",\n",
    "        \"question\": \"this is a mock question\",\n",
    "        \"options\": [\"the\", \"cake\", \"is a\", \"lie\"],\n",
    "        \"example_type\": \"race_middle_short\",\n",
    "    }\n",
    "]\n",
    "\n",
    "features = Features({\n",
    "    \"example_id\": Value(\"string\"),\n",
    "    \"article\": Value(\"string\"),\n",
    "    \"answer\": Value(\"string\"),\n",
    "    \"question\": Value(\"string\"),\n",
    "    \"options\": Sequence(Value(\"string\")),\n",
    "    \"example_type\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "# 각 타입별로 동일 레코드 100개씩 생성\n",
    "ds = [Dataset.from_list([record] * 100, features=features) for record in records]\n",
    "out_bases = [\"../_final/dataset/cloth\", \"../_final/dataset/korean\", \"../_final/dataset/race_high_long\", \"../_final/dataset/race_high_short\", \"../_final/dataset/race_middle_long\", \"../_final/dataset/race_middle_short\"]\n",
    "for i in range(len(ds)):\n",
    "    dsd = DatasetDict({\"train\": ds[i], \"test\": ds[i]})\n",
    "\n",
    "    out_dir = Path(out_bases[i])\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dsd.save_to_disk(str(out_dir))\n",
    "    print(out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
